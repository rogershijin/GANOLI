{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5abef350-a6fb-4d5b-8e31-acfb043bd5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing SquishTransformer: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing SquishTransformer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SquishTransformer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertModel\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "\n",
    "class SquishTransformer(DistilBertModel):\n",
    "    def forward(\n",
    "    self,\n",
    "    input_ids: Optional[torch.Tensor] = None,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    head_mask: Optional[torch.Tensor] = None,\n",
    "    inputs_embeds: Optional[torch.Tensor] = None,\n",
    "    output_attentions: Optional[bool] = None,\n",
    "    output_hidden_states: Optional[bool] = None,\n",
    "    return_dict: Optional[bool] = None,\n",
    ") -> Union[BaseModelOutput, Tuple[torch.Tensor, ...]]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embeddings(input_ids)  # (bs, seq_length, dim)\n",
    "            \n",
    "        \n",
    "        return self.transformer(\n",
    "            x=inputs_embeds,\n",
    "            attn_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    \n",
    "\n",
    "model = SquishTransformer.from_pretrained('distilbert-base-uncased', cache_dir=\"/om2/user/rogerjin/.cache\")\n",
    "model.embeddings.word_embeddings = torch.nn.Embedding(116490, 768)\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda:0'\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a50f72a1-4e4e-4a31-86d3-9993e50320ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.4954,  0.3014,  0.2405,  ..., -0.3716, -0.0344, -0.1476],\n",
       "         [ 0.5129,  0.5270,  0.1829,  ..., -0.4150,  0.0398, -0.0783]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[1,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "717d1e07-5605-412a-ae7e-db6c912032b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 64 × 116490\n",
       "    obs: 'nCount_peaks', 'atac_fragments', 'reads_in_peaks_frac', 'blacklist_fraction', 'nucleosome_signal', 'cell_type', 'pseudotime_order_ATAC', 'batch', 'pseudotime_order_GEX', 'is_train'\n",
       "    var: 'feature_types'\n",
       "    uns: 'dataset_id', 'gene_activity_var_names', 'organism', 'sample_pm_varnames'\n",
       "    obsm: 'gene_activity', 'lsi_full', 'lsi_red', 'umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "sc._settings.ScanpyConfig.n_jobs = 4\n",
    "\n",
    "atac_path = '/om2/user/rogerjin/data/NeurIPS2021/multiome/multiome_atac_processed_training_small.h5ad'\n",
    "atac = sc.read_h5ad(atac_path)\n",
    "atac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "343576c7-f467-4b53-84c2-4493335555b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "squish_and_embed() missing 1 required positional argument: 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c0ba87ca6d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msquish_and_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: squish_and_embed() missing 1 required positional argument: 'embeddings'"
     ]
    }
   ],
   "source": [
    "from anndata.experimental.pytorch import AnnLoader\n",
    "from squish_indexing import squish_and_embed\n",
    "\n",
    "dataloader = AnnLoader(atac, batch_size=8, shuffle=True, use_cuda=False)\n",
    "\n",
    "for batch in dataloader:\n",
    "    counts = batch.layers['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b2b01-e309-432a-a444-6954542811be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ganoli",
   "language": "python",
   "name": "ganoli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
