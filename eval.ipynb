{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "415365b7-3468-4096-a912-0e1f418dafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary.json', 'binary_highlr.json', 'binary_relu.json', 'cls.json', 'cls_highlr.json', 'cls_veryhighlr.json', 'default.json', 'num_workers.json', 'relu.json', 'test.json', 'test_config.py']\n",
      "/om2/user/rogerjin/GANOLI/configs/default.json\n",
      "{'batch_size': 32,\n",
      " 'epochs': 1000,\n",
      " 'lr': 0.0005,\n",
      " 'max_seq_len': 1600,\n",
      " 'run_name': 'default'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "checkpoint_dir = '/om2/user/rogerjin/checkpoints/'\n",
    "checkpoint_path = f'{checkpoint_dir}/super-wind-18/epoch=1-val_loss=12.54945.pt'\n",
    "cache_dir = '/om2/user/rogerjin/.cache'\n",
    "\n",
    "config_dir = '/om2/user/rogerjin/GANOLI/configs'\n",
    "print(os.listdir(config_dir))\n",
    "config_path = f'{config_dir}/default.json'\n",
    "print(config_path)\n",
    "config = json.load(open(config_path))\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e85c03e-7bcd-48b3-b101-41374584f4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'train/loss', 'train/best_loss', 'train/best_loss_epoch', 'val/loss', 'val/best_loss', 'val/best_loss_epoch'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d728c70-aeb7-40f4-9352-2c44bd4c6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig\n",
    "from torch.nn import Linear\n",
    "\n",
    "class SquishTransformer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim=13431):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased', cache_dir=cache_dir)\n",
    "        self.distilbert.embeddings.word_embeddings = torch.nn.Embedding(116491, 768) # todo: magic numbers\n",
    "        self.pre_classifier = Linear(self.distilbert.config.dim, self.distilbert.config.dim)\n",
    "        self.classifier = Linear(self.distilbert.config.dim, output_dim)\n",
    "        \n",
    "    def forward(self, **kwargs):\n",
    "        out = self.distilbert(**kwargs).last_hidden_state[:, 0] # embedding of cls\n",
    "        out = self.pre_classifier(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "model = SquishTransformer()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# device = 'cpu'\n",
    "device = 'cuda:0'\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82da0597-b68e-4992-8cf6-ea4a20537206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "remote_atac_dir = '/om2/user/rogerjin/data/NeurIPS2021/multiome/atac'\n",
    "remote_rna_dir = '/om2/user/rogerjin/data/NeurIPS2021/multiome/rna'\n",
    "remote_atac_path = '/om2/user/rogerjin/data/NeurIPS2021/multiome/multiome_atac_processed_training.h5ad'\n",
    "remote_rna_path = '/om2/user/rogerjin/data/NeurIPS2021/multiome/multiome_gex_processed_training.h5ad'\n",
    "\n",
    "atac = {\n",
    "#     'train': sc.read_h5ad(f'{remote_atac_dir}/atac_train_sorted_decreasing_variance.h5ad'),\n",
    "    'val': sc.read_h5ad(f'{remote_atac_dir}/atac_val_sorted_decreasing_variance.h5ad'),\n",
    "    'test': sc.read_h5ad(f'{remote_atac_dir}/atac_test_sorted_decreasing_variance.h5ad')\n",
    "}\n",
    "\n",
    "rna = {\n",
    "#     'train': sc.read_h5ad(f'{remote_rna_dir}/rna_train.h5ad'),\n",
    "    'val': sc.read_h5ad(f'{remote_rna_dir}/rna_val.h5ad'),\n",
    "    'test': sc.read_h5ad(f'{remote_rna_dir}/rna_test.h5ad')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700a5358-e7b6-4381-8535-434c19539586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': MuData object with n_obs × n_vars = 4249 × 129921\n",
       "   var:\t'feature_types'\n",
       "   2 modalities\n",
       "     atac:\t4249 x 116490\n",
       "       obs:\t'nCount_peaks', 'atac_fragments', 'reads_in_peaks_frac', 'blacklist_fraction', 'nucleosome_signal', 'cell_type', 'pseudotime_order_ATAC', 'batch', 'pseudotime_order_GEX', 'is_train'\n",
       "       var:\t'feature_types'\n",
       "       uns:\t'dataset_id', 'gene_activity_var_names', 'organism', 'sample_pm_varnames'\n",
       "       obsm:\t'gene_activity', 'lsi_full', 'lsi_red', 'umap'\n",
       "       layers:\t'counts'\n",
       "     rna:\t4249 x 13431\n",
       "       obs:\t'pct_counts_mt', 'n_counts', 'n_genes', 'size_factors', 'phase', 'cell_type', 'pseudotime_order_GEX', 'batch', 'pseudotime_order_ATAC', 'is_train'\n",
       "       var:\t'gene_ids', 'feature_types', 'genome'\n",
       "       uns:\t'dataset_id', 'organism'\n",
       "       obsm:\t'X_pca', 'X_umap'\n",
       "       layers:\t'counts',\n",
       " 'test': MuData object with n_obs × n_vars = 4250 × 129921\n",
       "   var:\t'feature_types'\n",
       "   2 modalities\n",
       "     atac:\t4250 x 116490\n",
       "       obs:\t'nCount_peaks', 'atac_fragments', 'reads_in_peaks_frac', 'blacklist_fraction', 'nucleosome_signal', 'cell_type', 'pseudotime_order_ATAC', 'batch', 'pseudotime_order_GEX', 'is_train'\n",
       "       var:\t'feature_types'\n",
       "       uns:\t'dataset_id', 'gene_activity_var_names', 'organism', 'sample_pm_varnames'\n",
       "       obsm:\t'gene_activity', 'lsi_full', 'lsi_red', 'umap'\n",
       "       layers:\t'counts'\n",
       "     rna:\t4250 x 13431\n",
       "       obs:\t'pct_counts_mt', 'n_counts', 'n_genes', 'size_factors', 'phase', 'cell_type', 'pseudotime_order_GEX', 'batch', 'pseudotime_order_ATAC', 'is_train'\n",
       "       var:\t'gene_ids', 'feature_types', 'genome'\n",
       "       uns:\t'dataset_id', 'organism'\n",
       "       obsm:\t'X_pca', 'X_umap'\n",
       "       layers:\t'counts'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ganoli.GanoliDataset import GanoliMultimodalDataset\n",
    "from muon import MuData\n",
    "\n",
    "class MuDataWithLen(MuData):\n",
    "    \n",
    "    def __len__(self):\n",
    "        try:\n",
    "            return self._len\n",
    "        except:\n",
    "            self._len = min(len(mod) for mod in self.mod.values())\n",
    "            return self._len\n",
    "\n",
    "datasets = {\n",
    "    partition: MuDataWithLen({'atac': atac[partition], 'rna': rna[partition]}) for partition in atac.keys()\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "711cac33-a37b-403c-9c45-7e793cb394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muon import MuData as md\n",
    "from torch.utils.data import DataLoader, BatchSampler, SequentialSampler, RandomSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "samplers = {\n",
    "    'train': RandomSampler,\n",
    "    'val': SequentialSampler,\n",
    "    'test': SequentialSampler\n",
    "}\n",
    "\n",
    "# todo: increase val/test batch size\n",
    "\n",
    "loaders = {\n",
    "    partition: DataLoader(dataset, sampler=BatchSampler(samplers[partition](dataset), batch_size=config['batch_size'], drop_last=False ), collate_fn=lambda x: x[0]) for partition, dataset in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c4a321c-4c35-4485-90ef-1be9c076666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from squish_indexing import squish_and_embed\n",
    "\n",
    "def forward_pass(batch, use_binary=config.get('use_binary', False)):\n",
    "    if use_binary:\n",
    "        atac = batch.mod['atac'].X.tocsr().tocoo()\n",
    "    else:\n",
    "        atac = batch.mod['atac'].layers['counts'].tocsr().tocoo()\n",
    "    squished = squish_and_embed(atac, model.distilbert.embeddings.word_embeddings, max_seq_len=config['max_seq_len'])\n",
    "    out = model(inputs_embeds=squished['embeddings'], attention_mask=squished['attention_mask'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a026d6b3-ee9e-4102-9a96-e0e543f4d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0049,  0.0184,  0.0211,  ...,  0.7366,  0.0163,  0.0040],\n",
       "        [-0.0043,  0.0189,  0.0208,  ...,  0.7265,  0.0169,  0.0040],\n",
       "        [ 0.0062,  0.0396,  0.0326,  ...,  0.4454,  0.0350,  0.0051],\n",
       "        ...,\n",
       "        [-0.0050,  0.0167,  0.0216,  ...,  0.7553,  0.0147,  0.0043],\n",
       "        [-0.0050,  0.0147,  0.0219,  ...,  0.7745,  0.0129,  0.0034],\n",
       "        [-0.0048,  0.0170,  0.0216,  ...,  0.7509,  0.0148,  0.0037]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in loaders['val']:\n",
    "    with torch.no_grad():\n",
    "        display(forward_pass(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4758f-8a12-4c67-ae13-bd3f77e6cff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ganoli",
   "language": "python",
   "name": "ganoli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
